Team: Frank Long & Colby Parkinson

Course: DAAN 897– Deep Learning (Spring II, 2020)

**Problem Statement**

The objective of our project was to enhance a convolution neural network (CNN) for classification of music genres by (i) adding Long-Short Term Memory (LSTM) to the model architecture, transforming the sample into 3-second stacked intervals, and implementing hypertuning and (ii) generalizing our updated model from GTZAN to Dortmund using transfer learning. We contextualize machine learning's applications for genre classification; describe how to pre-process audio data; detail the five models we tested using various components; present our transfer learning results; and demonstrate our model's strengths and weaknesses on four separate independent song samples.  

**Data Collection**

GTZAN: https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification

Dortmund: https://www-ai.cs.tu-dortmund.de/audio.html

**References to Data Sources**

GTZAN: Tzanetakis, G., and P. Cook. "Musical Genre Classification of Audio Signals." IEEE Transactions on Speech and Audio Processing 10, no. 5 (2002): 293-302. https://doi.org/10.1109/TSA.2002.800560.

Dortmund: Homburg, Helge, Ingo Mierswa, Bülent Möller, Katharina Morik, and Michael Wurst. "A Benchmark Dataset for Audio Classification and Clustering." Paper presented at the ISMIR, 2005.

**Code References**

CNN Base Model/Preprocessing: Guimarães, Heitor. "Gtzan.Keras." Updated 2022, 2018, 2022, https://github.com/Hguimaraes/gtzan.keras/issues. 

CNN+LSTM/Preprocessing: Sharma, Sahil. "Music-Genre-Classification" Updated 2020, 2019, 2022, https://github.com/sahilsharma884/Music-Genre-Classification.
